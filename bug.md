I am running into a local illegal memory access error with a Cuda kernel that reduces a 2d float32 tensor of size 1,32. Both the grid and the block dimensions were set to all 1, so it is just a single thread iterating over the tensor. Without print statements inside the kernel it does not trigger, but I get various confusing memory errors elsewhere. In pseudocode the reduce operation is essentially `fun a b -> if fst a > fst b then a else b` where `fst` just extracts the first element of the pair.

The kernel is itself is written in a new language called [Spiral](https://github.com/mrakgr/The-Spiral-Language/tree/tuple_reduce_bug) that compiles to both F# and Cuda. It compiles loops to tail recursive functions that it leaves to NVCC to optimize. This makes me a bit antsy as it is not something NVCC would have been likely to be thoroughly tested in.

Here is what I get when I run the program through memcheck.

```
========= Invalid __local__ write of size 4
=========     at 0x00000728 in method_5
=========     by thread (0,0,0) in block (0,0,0)
=========     Address 0x00fff87c is out of bounds
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_7 : 0x2e0)
=========     Device Frame:method_5 ($method_5$method_6 : 0x408)
=========     Device Frame:method_5 (method_5 : 0xb0)
=========     Saved host backtrace up to driver entry point at kernel launch time
=========     Host Frame:C:\WINDOWS\SYSTEM32\nvcuda.DLL (cuTexRefSetAddress + 0x1aa848) [0x1b7e95]
=========     Host Frame:[0x7ffc264f049e]
=========
========= Program hit CUDA_ERROR_LAUNCH_FAILED (error 719) due to "unspecified launch failure" on CUDA API call to cuMemcpyDtoH_v2.
=========     Saved host backtrace up to driver entry point at error
=========     Host Frame:C:\WINDOWS\SYSTEM32\nvcuda.DLL (cuTexRefSetAddress + 0x1b430f) [0x1c195c]
=========     Host Frame:[0x7ffc264f30cd]
=========
========= ERROR SUMMARY: 2 errors
``` 

That there would be an error by Spiral is unlikely because it is a high level functional language and I am doing no explicit mutation in the code nor assembly twiddling. And since the error is due to a local write, I am thinking the bug might be by the Cuda compiler.

The Spiral code used to run the program can be found in - https://github.com/mrakgr/The-Spiral-Language/tree/tuple_reduce_bug/Learning – in `Tests.fs`.

The code generated by it is in - https://github.com/mrakgr/The-Spiral-Language/blob/bb775a63a9443a102f325e8fbf180889bc2c04dd/Temporary/output.fs 

The whole thing is 350 lines, but that kernels are less than 100. It has print statements inserted inside it. As that tensor is really small, this cannot possibly be due to the device running out of memory.

I would like to narrow it down even futher by stepping into the ptx, but I am not sure how. Please tell me if more information is required.

Though `cub/cub.cuh` is included in the kernel, it can be ommited out as the kernel does not make use of it.