    inl layer_norm =
        inl fwd o i s =
            inl o_primal = s.CudaTensor.to_dev_tensor o.primal
            inl n = (primal i).dim |> snd |> HostTensor.span |> to float
            s.CudaKernel.map_d1_seq_broadcast {
                seq = 
                    {
                    redo=(+)
                    map_out=inl i sum -> i - sum / n
                    }
                    ,
                    {
                    map_in=inl v -> v*v
                    redo=(+)
                    map_out=inl v vv -> 
                        inl o = o_primal 0 .get
                        v / (sqrt (o*o + vv / n))
                    }
                } (primal i)

        inl bck o r i s =
            inl o = Struct.map s.CudaTensor.to_dev_tensor {o without block}
            inl n = (primal i).dim |> snd |> HostTensor.span |> to float
            s.CudaKernel.map_d1_seq_broadcast' {
                seq = 
                    {
                    map_in=inl _,i -> i
                    redo=(+)
                    map_out=inl er,i sum -> 
                        inl mean = sum / n
                        er,i - mean
                    }
                    ,
                    {
                    map_in=inl er,v -> v*v
                    redo=(+)
                    map_out=inl er,v vv -> 
                        inl o = o .primal 0 .get
                        er,v,sqrt (o*o + vv / n)
                    }
                    ,
                    {
                    map_in=inl er,v,div -> er * -v / (div * div)
                    redo=(+)
                    map_out=inl er,v,div er_div -> 
                        inl dv_top = er * div
                        dv_top,v,er_div * to float 0.5 / div
                    }
                    ,
                    {
                    map_in=inl _,_,div' -> div'
                    // redo' does not do broadcasting to the zeroth thread.
                    redo'=(+)
                    map_out=inl dv_top,v,div' er_div' -> 
                        if threadIdx.x = 0 then two * o.primal 0 .get * er_div' |> atomic_add (o.adjoint 0)
                        inl dv_div = div' * (two / n) * v 
                        dv_top + dv_div
                    }
                    ,
                    {
                    map_in=inl er -> -er
                    redo=(+)
                    map_out=inl er_i er_mean adjoint -> adjoint + er_i + er_mean / n
                    }
                } (r.adjoint, i.primal) i.adjoint

        inl init s = s.CudaTensor.zero {elem_type=float; dim=1} |> dr s

        inl activation o i s =
            inl r = fwd o i s |> dr s
            r, inl _ -> bck o r i s

        {fwd bck init activation} |> stackify